```{r setup, include = FALSE}
set.seed(1337)

library("tidymodels")
tidymodels::tidymodels_prefer()

library("tidyposterior")
library("rstanarm")


data("iris")
iris <- iris %>%
  tibble::as_tibble() %>% 
  filter(Species != "setosa") %>% 
  droplevels()

iris_split <- initial_split(iris, prop = 0.90)
iris_train <- training(iris_split)
iris_test <- testing(iris_split)
```

# Creating multiple models
## Cross-validation
The reasonings for, and theoretical aspects of, cross-validation (CV) are expected to be already known. In the `tidymodels` universe, CV is setup as:
```{r}
iris_folds <- vfold_cv(iris_train,
                       v = 10)
iris_folds
```



## Recipes
When it comes to modelling, creating and comparing multiple models is essential. This is easily achieved through the use of `recipe()` from the `recipes` package. A recipe is a collection of both a fomula and preprocessing steps. Here preprocessing steps is not applied, but could be: log-transforming data, creating dummy variables (e.g. one hot encoding) and sum up low occurring categories to handle class imbalance.

```{r}
SL_rec <- recipe(Species ~ Sepal.Length,
                 data = iris_train)

SLW_rec <- recipe(Species ~ Sepal.Length + Sepal.Width,
                  data = iris_train)

SLW_int_rec <- recipe(Species ~ Sepal.Length + Sepal.Width,
                      data = iris_train) %>%
  step_interact(~ Sepal.Length:Sepal.Width)

PL_rec <- recipe(Species ~ Petal.Length,
                 data = iris_train)

PLW_rec <- recipe(Species ~ Petal.Length + Petal.Width,
                  data = iris_train)

PLW_int_rec <- recipe(Species ~ Petal.Length + Petal.Width,
                      data = iris_train) %>%
  step_interact(~ Petal.Length:Petal.Width)

recipe_list <- list(SL = SL_rec,
                    SLW = SLW_rec,
                    SLW_int = SLW_int_rec,
                    PL = PL_rec,
                    PLW = PLW_rec,
                    PLW_int = PLW_int_rec)

lg_models <- workflow_set(preproc = recipe_list,
                          models = list(logistic = logistic_reg()),
                          cross = FALSE)
```

Each of the `v` folds are fitted with a `purr`-like workflow function:
```{r}
# To save the predicted values and used workflows
keep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)


lg_models <- lg_models %>% 
  workflow_map("fit_resamples",
               resamples = iris_folds,
               control = keep_pred,
               seed = 1337)
lg_models
```
## Evaluation metrics across models
Two simple evaluation metrics for logistic regressions are the accuracy and Area Under the Curve (AUC), in this case area under the Receiver Operating Characteristic (ROC) curve. To view these two evaluation metrics:
```{r}
collect_metrics(lg_models) %>% 
  select(-c(.config, preproc, .estimator)) %>% 
  filter(.metric == "accuracy") %>% 
  arrange(desc(mean))

collect_metrics(lg_models) %>% 
  select(-c(.config, preproc, .estimator)) %>% 
  filter(.metric == "roc_auc") %>% 
  arrange(desc(mean))
```
To illustrate the two metrics:
```{r}
lg_models %>% 
  autoplot(metric = "accuracy") +
  geom_label(aes(label = wflow_id)) +
  theme(legend.position = "none") +
  xlim(c(0.5, 6.5)) +
  ggtitle("Accuracy stratified on model")
  
lg_models %>% 
  collect_predictions() %>% 
  group_by(wflow_id) %>% 
  roc_curve(truth = Species,
            .pred_versicolor) %>% 
  autoplot() +
  ggtitle("ROC curve statified on model")
```

## Resample-to-resample component of variation (consider remove)
All the models are tested on the same v-folds. In some cases, different models tends to perform well on the same folds - this effect is called a resample-to-resample component of variation. We can numerically investigate these correlations by correlating each model estimates with eachother:
```{r}
lg_models %>% 
  collect_metrics(summarize = FALSE) %>% 
  filter(.metric == "accuracy") %>% 
  select(wflow_id, .estimate, id) %>% 
  pivot_wider(id_cols = "id",
              names_from = "wflow_id",
              values_from = ".estimate") %>%
  select(-id) %>% 
  corrr::correlate(quiet = TRUE)
```

The correlation illustrated:
```{r}
lg_models %>% 
  collect_metrics(summarize = FALSE) %>% 
  filter(.metric == "accuracy") %>% 
  mutate(wflow_id = reorder(wflow_id,
                            .estimate)) %>% 
  ggplot(aes(x = wflow_id,
             y = .estimate,
             group = id,
             color = id)) + 
  geom_line(alpha = .5,
            linewidth = 1.25) + 
  theme(legend.position = "none")
```
