Set seed and load packages.
```{r}
#| output: false
#| code-fold: true
#| code-summary: "Show the code"

set.seed(1337)

library("tidymodels")
tidymodels::tidymodels_prefer()
```

Load data.
```{r}
#| output: false
#| code-fold: true
#| code-summary: "Show the code"

data("iris")
iris <- iris |>
  tibble::as_tibble() |> 
  filter(Species != "setosa") |> 
  droplevels()
```

# Introduction to Tidy Modelling
## Introdution to dataset
For simplicity, the `iris` dataset is used since the structure is simple, and readers should be familiar with it. As a quick reminder, the dataset consists of five variables (columns) and 150 observations (rows). The first four variables are doubles describing the size of the flower, used as features. The last variable, the response, is a factor indicating the species of flower, used as the response. To make this a binary logistic classification problem, and not multiclass, the setosa species have been excluded.
```{r}
dim(iris)


iris |> 
  slice_head(n = 5) |>
  str()
```

## Training- and Test Set
As is customary when modeling, the dataset is split into a training- and testing set. It is needed to check for class imbalance in case some responses (here species) are more likely in the dataset. As seen from the plot below, it is not the case.
```{r}
iris |> 
  ggplot(aes(x = Species,
             fill = Species)) +
  geom_bar()
```

If a class imbalance was observed, using the `strata` argument should be used as in the below to ensure that the training- and testing set have the same distribution of the response variable. The `prop` argument indicates that 90% of the data is used for training and 10% for testing.
```{r}
#| eval: false

iris_split <- initial_split(iris,
                            prop = 0.90,
                            strata = Species)
iris_train <- training(iris_split)
iris_test <- testing(iris_split)
```

As it is not the case, just using the `prop` argument is sufficient.
```{r}
iris_split <- initial_split(iris,
                            prop = 0.90)
iris_train <- training(iris_split)
iris_test <- testing(iris_split)
```

## Fitting a model
The `parsnip` package standardizes creating models. When learning a new technique, here `parsnip`, it is a good idea to apply well known theory. Therefore, a linear logistic regression model is used to predict the species of a flower given the dimensions of the sepal and the petal. If the reader is unfamiliar with the theory, it is recommended to read the chapter on logistic regression (@sec-logistic_regression).
```{r}
lg_model <- logistic_reg()
```

Different packages contain different ways of applying a linear logistic regression model. The issues are more apparent for more advances models, where e.g. the arguments have different names or should be supplied in a different way. The `parsnip` package standardizes this. It is important to choose which engine to use - i.e. which package. The `show_engines()` function can be used to see which packages are available for the model. Here, the `glm` package is used.

```{r}
# Show available packages for the model
show_engines("logistic_reg")

lg_model <- lg_model |> 
  set_engine("glm")
```

Using the `formula` syntax, it is specified which variables are the features and the response. The `tidy()` function can be used to get a summary of the model in a tibble format.

```{r}
lg_fit <- lg_model |>
  fit(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
      data = iris_train)

lg_fit |> tidy()
```

## Prediction
Making predictions is also standardized and requires the function `predict()`. The model seem to predict correctly in all cases.
```{r}
iris_test |> 
  select(Species) |> 
  bind_cols(predict(lg_fit,
                    new_data = iris_test))
```

# Session Info

```{r}
sessioninfo::session_info()
```